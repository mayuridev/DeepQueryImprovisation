{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "musicML.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErZC36ZVr5t3"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PhNr2MVscEB"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmxzzIp4s4W8"
      },
      "source": [
        "cd /content/drive/MyDrive/MusicNotebook/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWAPl6Tj1e87"
      },
      "source": [
        "!apt-get install swig"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JFlldHW1KGC"
      },
      "source": [
        "cd python3-midi/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EiD5S781Pfx"
      },
      "source": [
        "!python setup.py install"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjNlmWkc1nvx"
      },
      "source": [
        "cd ../"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qk2gn174r5t9"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import msgpack\n",
        "import glob\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.ops import control_flow_ops\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import midi_manipulation\n",
        "\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAoMy3D63J7X"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FliulBaFr5t-"
      },
      "source": [
        "def get_songs(path):\n",
        "    files = glob.glob('{}/*.mid*'.format(path))\n",
        "    print(files)\n",
        "    songs = []\n",
        "    for f in tqdm(files):\n",
        "        print(f)\n",
        "        song = np.array(midi_manipulation.midiToNoteStateMatrix(f))\n",
        "        if np.array(song).shape[0] > 50:\n",
        "             songs.append(song)\n",
        "             print('gottcha')\n",
        "        else:\n",
        "             print(np.array(song).shape[0], 'no good')   \n",
        "    return songs"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQaCY7GZr5t_"
      },
      "source": [
        "songs = get_songs('/content/drive/MyDrive/MusicNotebook/mozart') #These songs have already been converted from midi to msgpack\n",
        "print(\"{} songs processed\".format(len(songs)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zA4NjfQr5uC"
      },
      "source": [
        "lowest_note = midi_manipulation.lowerBound #the index of the lowest note on the piano roll\n",
        "highest_note = midi_manipulation.upperBound #the index of the highest note on the piano roll\n",
        "note_range = highest_note-lowest_note #the note range\n",
        "\n",
        "num_timesteps  = 4 #64 #32 #16 #This is the number of timesteps that we will create at a time  (16 = one bar)\n",
        "n_visible      = 2*note_range*num_timesteps #This is the size of the visible layer. \n",
        "n_hidden       = 50 #50 #This is the size of the hidden layer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXBtdWSrr5uD"
      },
      "source": [
        "#x  = tf.placeholder(tf.float32, [None, n_visible], name=\"x\") #The placeholder variable that holds our data\n",
        "#W  = tf.Variable(tf.random_normal([n_visible, n_hidden], 0.01), name=\"W\") #The weight matrix that stores the edge weights\n",
        "#bh = tf.Variable(tf.zeros([1, n_hidden],  tf.float32, name=\"bh\")) #The bias vector for the hidden layer\n",
        "#bv = tf.Variable(tf.zeros([1, n_visible],  tf.float32, name=\"bv\")) #The bias vector for the visible layer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6BB6UY7r5uE"
      },
      "source": [
        "z_dim = n_hidden #100\n",
        "X_dim = n_visible #mnist.train.images.shape[1]\n",
        "h_dim = n_hidden #128\n",
        "\n",
        "print(X_dim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyabNvbgr5uF"
      },
      "source": [
        "def xavier_init(size):\n",
        "    in_dim = size[0]\n",
        "    xavier_stddev = 1. / tf.sqrt(in_dim / 2.)\n",
        "    return tf.random_normal(shape=size, stddev=xavier_stddev)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbSAhfEAr5uG"
      },
      "source": [
        "X = tf.placeholder(tf.float32, shape=[None, X_dim], name=\"X\")\n",
        "z = tf.placeholder(tf.float32, shape=[None, z_dim], name=\"z\")\n",
        "\n",
        "Q_b1 = tf.Variable(tf.zeros(shape=[h_dim]), name=\"Q_b1\")\n",
        "Q_W1 = tf.Variable(xavier_init([X_dim, h_dim]), name=\"Q_W1\")\n",
        "\n",
        "Q_W2_mu = tf.Variable(xavier_init([h_dim, z_dim]), name=\"Q_W2_mu\")\n",
        "Q_b2_mu = tf.Variable(tf.zeros(shape=[z_dim]), name=\"Q_b2_mu\")\n",
        "\n",
        "Q_W2_sigma = tf.Variable(xavier_init([h_dim, z_dim]),name=\"Q_W2_sigma\")\n",
        "Q_b2_sigma = tf.Variable(tf.zeros(shape=[z_dim]),name=\"Q_b2_sigma\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36V9LfpJlnyk"
      },
      "source": [
        "#def gaussian_noise_layer(input_layer, std):\n",
        "#    noise = tf.random_normal(shape=tf.shape(input_layer), mean=0.0, stddev=std, dtype=tf.float32) \n",
        "#    return input_layer + noise\n",
        "#noise = gaussian_noise_layer(X,1)\n",
        "#X = tf.add(X, noise)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiXIcrGpojqw"
      },
      "source": [
        "# Gaussian Noise\n",
        "gaussian_noise_layer = tf.random_normal(shape=tf.shape(X), mean=0.0, stddev=1.0, dtype=tf.float32) \n",
        "X = tf.add(X, gaussian_noise_layer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xv6E0T5Ar5uH"
      },
      "source": [
        "def Q(X):\n",
        "    h = tf.nn.relu(tf.matmul(X, Q_W1) + Q_b1)\n",
        "    z_mu = tf.matmul(h, Q_W2_mu) + Q_b2_mu\n",
        "    z_logvar = tf.matmul(h, Q_W2_sigma) + Q_b2_sigma\n",
        "    return z_mu, z_logvar\n",
        "\n",
        "\n",
        "def sample_z(mu, log_var):\n",
        "    eps = tf.random_normal(shape=tf.shape(mu))\n",
        "    return mu + tf.exp(log_var / 2) * eps"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhCEvvwQn3Wx"
      },
      "source": [
        "#mean, var = tf.nn.moments(X, axes=[1])\n",
        "#print(mean)\n",
        "#print(var)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEg1Cb8Sr5uJ"
      },
      "source": [
        "# =============================== P(X|z) ======================================\n",
        "\n",
        "P_W1 = tf.Variable(xavier_init([z_dim, h_dim]), name=\"P_W1\")\n",
        "P_b1 = tf.Variable(tf.zeros(shape=[h_dim]), name=\"P_b1\")\n",
        "\n",
        "P_b2 = tf.Variable(tf.zeros(shape=[X_dim]), name=\"P_b2\")\n",
        "P_W2 = tf.Variable(xavier_init([h_dim, X_dim]), name=\"P_W2\")\n",
        "\n",
        "\n",
        "# output value of decoder, both with linear output unit and logit unit\n",
        "def P(z):\n",
        "    h = tf.nn.relu(tf.matmul(z, P_W1) + P_b1)\n",
        "    logits = tf.matmul(h, P_W2) + P_b2\n",
        "    prob = tf.nn.sigmoid(logits)\n",
        "    return prob, logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLmTuGsRr5uK"
      },
      "source": [
        "z_mu, z_logvar = Q(X)\n",
        "z_sample = sample_z(z_mu, z_logvar)\n",
        "_, logits = P(z_sample)\n",
        "\n",
        "# Sampling from random z\n",
        "X_samples, _ = P(z)\n",
        "\n",
        "\n",
        "# E[log P(X|z)]\n",
        "recon_loss = tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=X), 1)\n",
        "# D_KL(Q(z|X) || P(z|X)); calculate in closed form as both dist. are Gaussian\n",
        "kl_loss = 0.5 * tf.reduce_sum(tf.exp(z_logvar) + z_mu**2 - 1. - z_logvar, 1)\n",
        "# VAE loss\n",
        "vae_loss = tf.reduce_mean(recon_loss + kl_loss)\n",
        "\n",
        "solver = tf.train.AdamOptimizer().minimize(vae_loss) #check learning rate\n",
        "\n",
        "#saver = tf.train.Saver()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "labJtOZ1r5uL"
      },
      "source": [
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "if not os.path.exists('out/'):\n",
        "    os.makedirs('out/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywNe66tjr5uM",
        "scrolled": true
      },
      "source": [
        "num_epochs = 20000 #The number of training epochs that we are going to run. For each epoch we go through the entire data set.\n",
        "batch_size = 100 #The number of training examples that we are going to send through the model at a time. \n",
        "# lr         = tf.constant(0.005, tf.float32) #The learning rate of our model\n",
        "\n",
        "i = 0\n",
        "loss_value = np.array([])\n",
        "iter_value = np.array([])\n",
        "songs = [songs[0]]\n",
        "while i <= num_epochs:\n",
        "    start_time = time.time()\n",
        "    for song in songs:\n",
        "        # The songs are stored in a time x notes format. The size of each song is timesteps_in_song x 2*note_range\n",
        "        # Here we reshape the songs so that each training example is a vector with num_timesteps x 2*note_range elements\n",
        "        song = np.array(song)\n",
        "        song = song[:np.floor(song.shape[0]/num_timesteps).astype(int)*num_timesteps]\n",
        "        song = np.reshape(song, [int(song.shape[0]/num_timesteps), song.shape[1]*num_timesteps])\n",
        "\n",
        "        # Train the VAE on batch_size examples at a time\n",
        "        for ind in range(0, len(song), batch_size): \n",
        "            X_mb = song[ind:ind+batch_size]\n",
        "            _, loss = sess.run([solver, vae_loss], feed_dict={X: X_mb})\n",
        "    \n",
        "    \n",
        "    if i % 100 == 0:\n",
        "        end_time = time.time()\n",
        "        log_str = '[Iter {}] '.format(i)\n",
        "        log_str += '[Loss {}]'.format(loss)\n",
        "        timeTaken = (end_time - start_time) * 100\n",
        "        log_str += '({:.3f} sec / 100 epoch)'.format(timeTaken)\n",
        "        print(log_str)\n",
        "        iter_value = np.append(iter_value, i)\n",
        "            \n",
        "        loss_value = np.append(loss_value, loss)\n",
        "\n",
        "        print(iter_value)\n",
        "        print(loss_value)\n",
        "        plt.figure(figsize=(8, 8))\n",
        "        plt.plot(iter_value, loss_value, 'o-')\n",
        "        \n",
        "        plt.show() \n",
        "        \n",
        "    if i % 1000 == 0:\n",
        "        samples = sess.run(X_samples, feed_dict={z: np.random.randn(1,z_dim)})\n",
        "        S = np.reshape(samples, (num_timesteps, 2*note_range))\n",
        "        thresh_S = S>=0.5\n",
        "        plt.figure(figsize=(12,2))\n",
        "        plt.subplot(1,2,1)\n",
        "        plt.imshow(S)\n",
        "        plt.subplot(1,2,2)\n",
        "        plt.imshow(thresh_S)\n",
        "        plt.tight_layout()\n",
        "        plt.pause(0.1)\n",
        "        #midi_manipulation.noteStateMatrixToMidi(thresh_S, \"out/generated_chord_{}\".format(i))\n",
        "#                 print(i)\n",
        "        \n",
        "       \n",
        "    i += 1\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pKdYgk6za_q"
      },
      "source": [
        "from scipy.optimize import curve_fit\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import FunctionTransformer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxbDCif8OZI7"
      },
      "source": [
        "x_samp = iter_value\n",
        "y_samp = loss_value"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azzIkCs2N266"
      },
      "source": [
        "print(y_samp)\n",
        "y_samp = np.delete(y_samp, 0)\n",
        "print(y_samp.size)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-ebLwNHO3LC"
      },
      "source": [
        "print(x_samp.size)\n",
        "x_samp = np.delete(x_samp, 149)\n",
        "print(x_samp.size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDBqssyoQIM9"
      },
      "source": [
        "def func( x_samp, a, b, c, d ):\n",
        "\treturn a*np.log( b*x_samp + c ) + d\n",
        "\n",
        "\n",
        "yn = y_samp + 0.2*np.random.normal(size=len(x_samp))\n",
        "\n",
        "popt, pcov = curve_fit(func, x_samp, yn)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(15, 15))\n",
        "plt.plot(x_samp, yn, 'bo', label=\"Original Noised Data\")\n",
        "plt.plot(x_samp, func(x_samp, *popt), 'r-', label=\"Fitted Curve\")\n",
        "plt.xlabel(\"Batch Iteration\")\n",
        "plt.ylabel(\"Loss Values with Noise\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPWuMXnZUyAb"
      },
      "source": [
        "import statistics\n",
        "def variance(data):\n",
        "  n = len(data)\n",
        "  mean = sum(data) / n\n",
        "  deviations = [(x - mean) ** 2 for x in data]\n",
        "  variance = sum(deviations) / n\n",
        "  return variance\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfxXGB5AVKg1"
      },
      "source": [
        "statistics.stdev(loss_value)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aOY_Bz9r5uO"
      },
      "source": [
        "saver = tf.train.Saver()\n",
        "\n",
        "#Save just in case\n",
        "mname = 'model'+'_h'+str(n_hidden)+'nt'+str(num_timesteps)\n",
        "save_path = saver.save(sess, \"./tmp/\"+mname+\".ckpt\")\n",
        "print(\"Model saved in path: %s\" % save_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIP6ZLf_r5uP"
      },
      "source": [
        "## Training Ended\n",
        "# Generative Part Starts Here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sfqvo92jr5uP"
      },
      "source": [
        "#tf.reset_default_graph()\n",
        "#imported_graph = tf.train.import_meta_graph(\"./tmp/\"+mname+\".ckpt.meta\")\n",
        "\n",
        "#saver = tf.train.Saver()\n",
        "#restore_path = saver.restore(sess, \"./tmp/\"+mname+\".ckpt\")\n",
        "\n",
        "#sess = tf.Session()\n",
        "#imported_graph.restore(sess, tf.train.latest_checkpoint(\"./tmp/\")\n",
        "#imported_graph.restore(sess, \"./tmp/\"+mname+\".ckpt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLacfUey-Tta"
      },
      "source": [
        "#def gaussian_noise_layer(input_layer, std):\n",
        " #   noise = tf.random_normal(shape=tf.shape(input_layer), mean=0.0, stddev=std, dtype=tf.float32) \n",
        " #   return input_layer + noise\n",
        "#\n",
        "#noise = gaussian_noise_layer(z, 49)\n",
        "#noise.eval(session=tf.Session(), feed_dict={z: np.zeros((4, 50))})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uARswmXpr5uQ"
      },
      "source": [
        "bars = int(25*16/num_timesteps)\n",
        "print(bars, z_dim)\n",
        "samples = sess.run(X_samples, feed_dict={z: np.random.randn(bars,z_dim)})\n",
        "S = np.reshape(samples, (bars*num_timesteps, 2*note_range))\n",
        "thresh_S = S>=0.5 #0.5 # threshold\n",
        "midi_manipulation.noteStateMatrixToMidi(thresh_S, \"out/generated_chord_long\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7ub5QTQNLQo"
      },
      "source": [
        "from mpl_toolkits.mplot3d import axes3d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-UcoNlwr5uR"
      },
      "source": [
        "vn = 1\n",
        "q = \"/content/drive/MyDrive/MusicNotebook/haydn/hob1\"+\".mid\"\n",
        "# q = \"/content/drive/MyDrive/naruto/n2.mid\"\n",
        "querysong = np.array(midi_manipulation.midiToNoteStateMatrix(q))\n",
        "print(np.shape(querysong))\n",
        "plt.figure(figsize=(20, 20))\n",
        "plt.imshow(querysong.T)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwv59UkEr5uR"
      },
      "source": [
        "song = np.array(querysong)\n",
        "zeropadsong = np.zeros(((np.floor(song.shape[0]/num_timesteps).astype(int)+1)*num_timesteps, song.shape[1]))\n",
        "zeropadsong[:song.shape[0],:song.shape[1]] = song\n",
        "#song = song[:(np.floor(song.shape[0]/num_timesteps).astype(int)+1)*num_timesteps]\n",
        "song = np.reshape(zeropadsong, [int(song.shape[0]/num_timesteps)+1, song.shape[1]*num_timesteps])\n",
        "print(np.shape(song))\n",
        "\n",
        "decode_bars = np.shape(song)[0]\n",
        "S_reconstruct = np.reshape(song, (decode_bars*num_timesteps, 2*note_range))\n",
        "\n",
        "midi_manipulation.noteStateMatrixToMidi(S_reconstruct, \"out/song_reconstruct\"+\"_vf\"+str(vn))   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKNObiKpr5uT"
      },
      "source": [
        "# Encode the VAE on query\n",
        "# These are the functions for Encoding-Decoding\n",
        "# Encoding: Reading from Data to get z_sample\n",
        "#z_mu, z_logvar = Q(X)\n",
        "#z_sample = sample_z(z_mu, z_logvar)\n",
        "# Decoding: Sampling from z\n",
        "#X_samples, _ = P(z)\n",
        "\n",
        "Xq = song\n",
        "zs = True\n",
        "if zs:\n",
        "    zq_sample = sess.run(z_sample, feed_dict={X: Xq})\n",
        "    ztype = \"_zs\"\n",
        "else: #using the mean instead of sampling: \n",
        "    zq_sample = sess.run(z_mu, feed_dict={X: Xq})  #Check why this causes breaks / missing values in the output\n",
        "    ztype = \"_zmu\"\n",
        "print(np.shape(zq_sample))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrWFGUeTr5uV"
      },
      "source": [
        "# Decode with the z from query\n",
        "samples = sess.run(X_samples, feed_dict={z: zq_sample})\n",
        "\n",
        "S = np.reshape(samples, (decode_bars*num_timesteps, 2*note_range))\n",
        "thresh_S = S>=0.857 #0.857 #0.5\n",
        "fout = \"generated_query\"+'_h'+str(n_hidden)+'_nt'+str(num_timesteps)+str(ztype)+\"_vf\"+str(vn)\n",
        "print(fout)\n",
        "midi_manipulation.noteStateMatrixToMidi(thresh_S, \"out/\"+fout)   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzEVIqFer5uX"
      },
      "source": [
        "plt.figure(figsize=(30,10))\n",
        "plt.imshow(np.log(np.abs(zq_sample)))\n",
        "print(np.shape(zq_sample))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}